# Matrix0 V2 Production Configuration
# Optimized for performance and strong play

model:
  # V2 Architecture Features
  planes: 19                       # Input planes for chess board
  channels: 320                    # Number of channels in residual blocks (32M model)
  blocks: 24                       # Number of residual blocks (32M model)
  attention_heads: 20              # Number of attention heads (32M model)
  policy_size: 4672                # Policy output size
  norm: "group"                    # GroupNorm instead of BatchNorm
  activation: "silu"               # SiLU activation instead of ReLU
  preact: true                     # Pre-activation residual blocks
  droppath: 0.1                    # DropPath regularization
  policy_factor_rank: 128          # Factorized policy head (32M model)
  aux_policy_from_square: true     # Auxiliary from-square prediction
  aux_policy_move_type: true       # Auxiliary move-type prediction
  ssl_curriculum: true             # Self-supervised learning curriculum
  self_supervised: true            # Enable SSL
  ssl_tasks: ["piece"]            # Enable piece SSL head (stable)
  ssrl_tasks: []                   # Keep SSRL off for now (optional)

selfplay:
  num_workers: 4                   # Four workers for intensive self-play generation
  batch_size: 128                  # Larger batches for efficiency
  max_games: 500                   # Generate 500 games for robust training data
  max_game_len: 100                # Shorter games for faster generation
  min_resign_plies: 20             # Earlier resignation for speed
  resign_threshold: -0.90          # More aggressive resignation
  num_simulations: 200             # 200 simulations for good move quality
  draw:
    min_plies: 30                  # Minimum plies before draw
    window: 12                     # Draw detection window
    min_unique: 4                  # Minimum unique positions
    halfmove_cap: 50               # Halfmove clock cap

training:
  batch_size: 128                  # Reduced for MPS memory headroom
  epochs: 3                        # More training epochs for efficiency
  learning_rate: 0.001
  weight_decay: 0.0001
  checkpoint_dir: "checkpoints"    # Directory for checkpoints
  checkpoint: "v2_base.pt"         # Use our fresh V2 base checkpoint
  gradient_accumulation_steps: 1   # Reduce graph lifetime on MPS
  grad_clip_norm: 0.5              # More aggressive gradient clipping to prevent NaN
  ssl_weight: 0.05                 # Reduced SSL weight to focus on stability
  ssl_warmup_steps: 200            # Longer SSL warmup for stability
  ssl_chunk_size: 16               # Smaller SSL chunks to prevent OOM
  precision: "fp16"                # Optimized mixed precision
  use_amp: true                    # Enable automatic mixed precision
  warmup_steps: 200                # Shorter warmup for faster convergence
  memory_limit_gb: 14              # Increase MPS memory limit to 14GB
  gradient_checkpointing_strategy: "tower_only"  # Always checkpoint tower for lower memory
  steps_per_epoch: 4000            # Explicit steps per orchestrator epoch
  use_curriculum: true
  curriculum_phases:
    - { name: openings, steps: 1500, description: "Bootstrap with openings-heavy data" }
    - { name: mixed,    steps: 6500, description: "Blend external + self-play" }
  policy_masking: false            # TEMPORARILY DISABLED - investigating zero policy targets

orchestrator:
  initial_games: 500               # Generate all 500 games in initial phase
  subsequent_games: 0              # No additional games needed
  games_per_cycle: 500             # Handle all games in one cycle
  train_epochs_per_cycle: 1        # Single training epoch for large dataset
  eval_games_per_cycle: 20         # Evaluate 20 games for quality check
  keep_top_k: 1                    # Keep only best model
  continuous_mode: false           # Single run mode
  checkpoint_override: "v2_base.pt"  # Override default best.pt with fresh V2 base checkpoint
  tui: "table"                     # Use table display mode
  ui:
    compact: true                  # Child processes log to files; console stays clean

eval:
  games: 4                         # More evaluation games
  num_simulations: 800             # Production simulations
  max_moves: 80                    # Reasonable move limit
  external_engines: ["stockfish"]  # Compare against Stockfish
  tournament_rounds: 4             # More tournament rounds
  strength_estimation_games: 4     # More strength estimation games

mcts:
  num_simulations: 200              # Match self-play config for consistency
  cpuct: 2.2
  cpuct_start: 2.8
  cpuct_end: 1.8
  cpuct_plies: 40
  dirichlet_alpha: 0.3
  dirichlet_frac: 0.25
  dirichlet_plies: 16
  selection_jitter: 0.01
  fpu: 0.2
  draw_penalty: -0.2
  tt_capacity: 1000000
  tt_cleanup_frequency: 500
  tt_memory_limit_mb: 1024
  batch_size: 32
  encoder_cache: true
  legal_softmax: false
  max_children: 0
  min_child_prior: 0.0
  no_instant_backtrack: true
  parent_q_init: true
  tt_cleanup_interval_s: 5
  value_from_white: false
  virtual_loss: 2.0
  enable_memory_cleanup: true
  memory_cleanup_threshold_mb: 512
  max_tree_nodes: 50000
  # FIXED: Parallel MCTS with robust error handling and deadlock prevention
  num_threads: 4                   # Match worker count for efficiency
  parallel_simulations: true
  simulation_batch_size: 16
  tree_parallelism: true

presets:
  mps:
    device: "mps"
    num_threads: 4  # Match worker count
    inference_batch_size: 32
    mcts_threads: 4  # Match worker count
    worker_threads: 1  # 1 core per worker for 4 workers
